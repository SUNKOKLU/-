{\rtf1\ansi\ansicpg950\cocoartf1671
{\fonttbl\f0\froman\fcharset0 TimesNewRomanPSMT;\f1\fmodern\fcharset0 CourierNewPSMT;\f2\fswiss\fcharset0 Helvetica;
\f3\fnil\fcharset136 PingFangTC-Regular;\f4\fnil\fcharset134 PingFangSC-Regular;}
{\colortbl;\red255\green255\blue255;\red253\green128\blue8;\red255\green255\blue255;}
{\*\expandedcolortbl;;\cssrgb\c100000\c57637\c0;\cssrgb\c100000\c100000\c100000;}
{\info
{\title Import Settings:}
{\author Katie Habib}
{\*\company John Wiley and Sons, Inc.}}\margl1440\margr1440\vieww28140\viewh15160\viewkind1
\deftab720
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardeftab720\ri0\partightenfactor0

\f0\fs24 \cf0 Import Settings: \
Base Settings: Brownstone Default\
Highest Answer Letter: D\
Multiple Keywords in Same Paragraph: No\
\pard\pardeftab720\ri0\partightenfactor0
\cf0 \
\
\
Chapter: Chapter 4\
\
\
\
Multiple Choice\
\
\
\
1.  ____ is a thread library for Solaris that maps many user-level threads to one kernel thread.\
A)  Pthreads\
B)  Green threads\
C)  Sthreads\
D)  Java threads\
\
Ans:  B\
Feedback: 4.3.1\
Difficulty: Medium\
\
\
\
2.  Pthreads refers to ____.\
A)  the POSIX standard.\
B)  an implementation for thread behavior.\
C)  a specification for thread behavior.\
D)  an API for process creation and synchronization.\
\
Ans:  C\
Feedback: 4.4.1\
Difficulty: Medium\
\
\
\
3.  The ____ multithreading model multiplexes many user-level threads to a smaller or equal number of kernel threads.\
A)  many-to-one model\
B)  one-to-one model\
C)  many-to-many model\
D)  many-to-some model\
\
Ans:  C\
Feedback: 4.3.3\
Difficulty: Easy\
\
\
\
4.  Cancellation points are associated with ____ cancellation.\
A)  asynchronous\
B)  deferred\
C)  synchronous\
D)  non-deferred\
\
Ans:  B\
Feedback: 4.6.3\
Difficulty: Medium\
\
\
\
5.  Which of the following would be an acceptable signal handling scheme for a multithreaded program?\
A)  Deliver the signal to the thread to which the signal applies.\
B)  Deliver the signal to every thread in the process.\
C)  Deliver the signal to only certain threads in the process.\
D)  All of the above\
\
Ans:  D\
Feedback: 4.6.2\
Difficulty: Medium\
\
\
\
6.  Signals can be emulated in windows through ____.\
A)  asynchronous procedure calls\
B)  local procedure calls\
C)  remote procedure calls\
D)  none of the above\
\
Ans:  A\
Feedback: 4.6.2\
Difficulty: Medium\
\
\
\
7.  Thread-local storage is data that ____.\
A)  is not associated with any process\
B)  has been modified by the thread, but not yet updated to the parent process\
C)  is generated by the thread independent of the thread's process\
D)  is unique to each thread\
\
Ans:  D\
Feedback: 4.6.4\
Difficulty: Medium\
\
\
\
8.  LWP is ____.\
A)  short for lightweight processor\
B)  placed between system and kernel threads\
C)  placed between user and kernel threads\
D)  common in systems implementing one-to-one multithreading models\
\
Ans:  C\
Feedback: 4.6.5\
Difficulty: Easy\
\
\
\
9.  Windows uses the ____.\
A)  one-to-one model\
B)  many-to-one model\
C)  one-to many-model\
D)  many-to-many model\
\
Ans:  A\
Feedback: 4.7.1\
Difficulty: Easy\
\
\
\
10.  In multithreaded programs, the kernel informs an application about certain events using a procedure known as a(n) ____.\
A)  signal\
B)  upcall\
C)  event handler\
D)  pool\
\
Ans:  B\
Feedback: 4.6.5\
Difficulty: Medium\
\
\
\
11.  _____ is not considered a challenge when designing applications for multicore systems.\
A)  Deciding which activities can be run in parallel\
B)  Ensuring there is a sufficient number of cores\
C)  Determining if data can be separated so that it is accessed on separate cores\
D)  Identifying data dependencies between tasks.\
\
Ans: B\
Feedback: 4.2.1\
Difficulty: Medium\
\
\
\
12. A ____ provides an API for creating and managing threads.\
A) set of system calls\
B) multicore system\
C) thread library\
D) multithreading model\
\
Ans: C\
Feedback: 4.4\
Difficulty: Easy\
\
\
\
13. The _____ model multiplexes many user-level threads to a smaller or equal number of kernel threads.\
A) many-to-many\
B) two-level\
C) one-to-one\
D) many-to-one\
\
Ans: A\
Feedback: 4.3.3\
Difficulty: Easy\
\
\
\
14. The _____ model maps many user-level threads to one kernel thread.\
A) many-to-many\
B) two-level\
C) one-to-one\
D) many-to-one\
\
Ans: D\
Feedback: 4.3.1\
Difficulty: Easy\
\
\
\
15. The _____ model maps each user-level thread to one kernel thread.\
A) many-to-many\
B) two-level\
C) one-to-one\
D) many-to-one\
\
Ans: C\
Feedback: 4.3.2\
Difficulty: Easy\
\
\
\
16. The _____ model allows a user-level thread to be bound to one kernel thread.\
A) many-to-many\
B) two-level\
C) one-to-one\
D) many-to-one\
\
Ans: B\
Feedback: 4.3.3\
Difficulty: Easy\
\
\
\
17. The most common technique for writing multithreaded Java programs is _____.\
A) extending the 
\f1\fs20 Thread
\f0\fs24  class and overriding the 
\f1\fs20 run()
\f0\fs24  method\
B) implementing the 
\f1\fs20 Runnable
\f0\fs24  interface and defining its 
\f1\fs20 run()
\f0\fs24  method\
C) designing your own 
\f1\fs20 Thread
\f0\fs24  class\
D) using the 
\f1\fs20 CreateThread()
\f0\fs24  function\
\
Ans: B\
Feedback: 4.4.3\
Difficulty: Easy\
\
\
\
18. In Pthreads, a parent uses the 
\f1\fs20 pthread_join()
\f0\fs24  function to wait for its child thread to complete. What is the equivalent function in Win32?\
A) 
\f1\fs20 win32_join()
\f0\fs24 \
B) 
\f1\fs20 wait()
\f0\fs24 \
C) 
\f1\fs20 WaitForSingleObject()
\f0\fs24 \
D) 
\f1\fs20 join()
\f0\fs24 \
\
Ans: C\
Section 4.4.2\
Difficulty: Medium\
\
\
\
19. Which of the following statements regarding threads is false?\
A) Sharing is automatically provided in Java threads.\
B) Both Pthreads and Win32 threads share global data.\
C) The 
\f1\fs20 start()
\f0\fs24  method actually creates a thread in the Java virtual machine.\
D) The Java method 
\f1\fs20 join()
\f0\fs24  provides similar functionality as the 
\f1\fs20 WaitForSingleObject
\f0\fs24  in Win32.\
\
Ans: A\
Feedback: 4.4.3\
Difficulty: Medium\
\
\
\
20. A _____ uses an existing thread \'97 rather than creating a new one \'97 to complete a task.\
A) lightweight process\
B) thread pool\
C) scheduler activation\
D) asynchronous procedure call\
\
Ans: B\
Feedback: 4.5.1\
Difficulty: Easy\
\
\
\
21. According to Amdahl's Law, what is the speedup gain for an application that is 60% parallel and we run it on a machine with 4 processing cores?\
A) 1.82\
B) .7\
C) .55\
D) 1.43\
\
Ans: D\
Feedback: 4.2\
Difficulty: Medium\
\
\
\
22. _________ involves distributing tasks across multiple computing cores.\
A) Concurrency\
B) Task parallelism\
C) Data parallelism\
D) Parallelism\
\
Ans: B\
Feedback: 4.2.2\
Difficulty: Medium\
\
\
\
23. ___________ is a formula that identifies potential performance gains from adding additional computing cores to an application that has a parallel and serial component.\
A) Task parallelism\
B) Data parallelism\
C) Data splitting\
D) Amdahl's Law\
\
Ans: D\
Feedback: 4.2\
Difficulty: Medium\
\
\
\
24. When OpenMP encounters the 
\f1 #pragma omp parallel
\f0  directive, it\
A) constructs a parallel region\
B) creates a new thread\
C) creates as many threads as there are processing cores\
D) parallelizes 
\f1 for
\f0  loops\
\
Ans: C\
Feedback: 4.5.2\
Difficulty: Medium\
\
\
\
25. Grand Central Dispatch handles blocks by\
A) placing them on a dispatch queue\
B) creating a new thread\
C) placing them on a dispatch stack\
D) constructing a parallel region\
\
Ans: A\
Feedback: 4.5.3\
Difficulty: Medium\
\
\
\
Essay\
\
\
\
26.  Why should a web server not run as a single-threaded process?\
\
Ans:  For a web server that runs as a single-threaded process, only one client can be serviced at a time. This could result in potentially enormous wait times for a busy server. \
Feedback: 4.1.1\
Difficulty: Medium\
\
\
\
27.  List the four major categories of the benefits of multithreaded programming. Briefly explain each.\
\
Ans:  The benefits of multithreaded programming fall into the categories: responsiveness, resource sharing, economy, and utilization of multiprocessor architectures. Responsiveness means that a multithreaded program can allow a program to run even if part of it is blocked. Resource sharing occurs when an application has several different threads of activity within the same address space. Threads share the resources of the process to which they belong. As a result, it is more economical to create new threads than new processes. Finally, a single-threaded process can only execute on one processor regardless of the number of processors actually present. Multiple threads can run on multiple processors, thereby increasing efficiency.\
Feedback: 4.1.2\
Difficulty: Difficult\
\
\
\
28.  What are the two different ways in which a thread library could be implemented?\
\
Ans:  The first technique of implementing the library involves\cf2 \cb3  ensuring that all code and data structures for the library reside in user space with no kernel support. T\cf0 \cb1 he other approach is to implement \cf2 a kernel-level library supported directly by the operating system so that the code and data structures exist in kernel space.\cf0 \
Feedback: 4.4\
Difficulty: Medium\
\
\
\
29.  Describe two techniques for creating 
\f1\fs20 Thread
\f0\fs24  objects in Java.\
\
Ans:  One approach is to create a new class that is derived from the 
\f1\fs20 Thread
\f0\fs24  class and to override its 
\f1\fs20 run()
\f0\fs24  method.  An alternative \'97 and more commonly used \'97 technique is to define a class that implements the 
\f1\fs20 Runnable
\f0\fs24  interface.  When a class implements 
\f1\fs20 Runnable
\f0\fs24 , it must define a 
\f1\fs20 run()
\f0\fs24  method.  The code implementing the 
\f1\fs20 run()
\f0\fs24  method is what runs as a separate thread.\
Feedback: 4.4.3\
Difficulty: Medium\
\
\
\
30.  In Java, what two things does calling the 
\f1\fs20 start()
\f0\fs24  method for a new 
\f1\fs20 Thread
\f0\fs24  object accomplish?\
\
Ans:  Calling the 
\f1\fs20 start()
\f0\fs24  method for a new 
\f1\fs20 Thread
\f0\fs24  object first allocates memory and initializes a new thread in the JVM. Next, it calls the 
\f1\fs20 run()
\f0\fs24  method, making the thread eligible to be run by the JVM. Note that the 
\f1\fs20 run()
\f0\fs24  method is never called directly. Rather, the 
\f1\fs20 start()
\f0\fs24  method is called, which then calls the 
\f1\fs20 run()
\f0\fs24  method.\
Feedback: 4.4.3\
Difficulty: Medium\
\
\
\
31.  Some UNIX systems have two versions of 
\f1\fs20 fork()
\f0\fs24 . Describe the function of each version, as well as how to decide which version to use.\
\
Ans:  One version of 
\f1\fs20 fork()
\f0\fs24  duplicates all threads and the other duplicates only the thread that invoked the 
\f1\fs20 fork()
\f0\fs24  system call. Which of the two versions of 
\f1\fs20 fork()
\f0\fs24  to use depends on the application. If 
\f1\fs20 exec()
\f0\fs24  is called immediately after forking, then duplicating all threads is unnecessary, as the program specified in the parameters to 
\f1\fs20 exec()
\f0\fs24  will replace the process. If, however, the separate process does not call 
\f1\fs20 exec()
\f0\fs24  after forking, the separate process should duplicate all threads.\
Feedback: 4.6.1\
Difficulty: Difficult\
\
\
\
32.  How can deferred cancellation ensure that thread termination occurs in an orderly manner as compared to asynchronous cancellation?\
\
Ans:  In asynchronous cancellation, the thread is immediately cancelled in response to a cancellation request. There is no insurance that it did not quit in the middle of a data update or other potentially dangerous situation. In deferred cancellation, the thread polls whether or not it should terminate. This way, the thread can be made to cancel at a convenient time. \
Feedback: 4.6.3\
Difficulty: Medium\
\
\
\
33.  What is a thread pool and why is it used?\
\
Ans:  A thread pool is a collection of threads, created at process startup, that sit and wait for work to be allocated to them. This allows one to place a bound on the number of concurrent threads associated with a process and reduce the overhead of creating new threads and destroying them at termination.\
Feedback: 4.5.1\
Difficulty: Medium\
\
\
\
34.  What are the general components of a thread in Windows?\
\
Ans:  The thread consists of a unique ID, a register set that represents the status of the processor, a user stack for user mode, a kernel stack for kernel mode, and a private storage area used by run-time libraries and dynamic link libraries. \
Feedback: 4.4.2\
Difficulty: Medium\
\
\
\
35.  Describe the difference between the 
\f1\fs20 fork()
\f0\fs24  and 
\f1\fs20 clone()
\f0\fs24  Linux system calls.\
\
Ans:  The 
\f1\fs20 fork()
\f0\fs24  system call is used to duplicate a process. The 
\f1\fs20 clone()
\f0\fs24  system call behaves similarly except that, instead of creating a copy of the process, it creates a separate process that shares the address space of the calling process.\
Feedback: 4.7.2\
Difficulty: Medium\
\
\
\
36. Multicore systems present certain challenges for multithreaded programming. Briefly describe these challenges.\
\
Ans: Multicore systems have placed more pressure on system programmers as well as application developers to make efficient use of the multiple computing cores. These challenges include determining how to divide applications into separate tasks that can run in parallel on the different cores. These tasks must be balanced such that each task is doing an equal amount of work. Just as tasks must be separated, data must also be divided so that it can be accessed by the tasks running on separate cores. So that data can safely be accessed, data dependencies must be identified and where such dependencies exist, data accesses must be synchronized to ensure the safety of the data. Once all such challenges have been met, there remains considerable challenges testing and debugging such applications.\
Feedback: 4.2.1\
Difficulty: Difficult\
\
\
\
37. Distinguish between parallelism and concurrency.\
\
Ans: A parallel system can perform more than one task simultaneously. A concurrent system supports more than one task by allowing multiple tasks to make progress. \
Feedback: 4.2\
Difficulty: Medium\
\
\
\
38. Distinguish between data and task parallelism.\
\
And: Data parallelism involves distributing subsets of the same data across multiple computing cores and performing the same operation on each core. Task parallelism involves distributing tasks across the different computing cores where each task is performing a unique operation.\
Feedback: 4.2.2\
Difficulty: Difficult\
\
\
\
39. Describe how OpenMP is a form of implicit threading.\
\
Ans: OpenMP provides a set of compiler directives that allows parallel programming on systems that support shared memory. Programmers identify regions of code that can run in parallel by placing them in a block of code that begins with the directive 
\f1 #pragma omp parallel
\f0 . When the compiler encounters this parallel directive, it creates as many threads as there are processing cores in the system.\
Feedback: 4.5.2\
Difficulty: Difficult\
\
\
\
40. Describe how Grand Central Dispatch is a form of implicit threading.\
\
Ans: Grand Central Dispatch (GCD) is a technology for Mac OS X and iOS systems that is a combination of extensions to the C language, an API, and a runtime library that allows developers to construct "blocks" -  regions of code that can run in parallel. GCD then manages the parallel execution of blocks in several dispatch queues.\
Feedback: 4.5.3\
Difficulty: Difficult\
\
\
\
True/False\
\
\
\
41.  A traditional (or heavyweight) process has a single thread of control. \
\
Ans:  True\
Feedback: 4.1\
Difficulty: Easy\
\
\
\
42.  A thread is composed of a thread ID, program counter, register set, and heap.\
\
Ans:  False\
Feedback: 4.1\
Difficulty: Medium\
\
\
\
43.  Virtually all contemporary operating systems support kernel threads.\
\
Ans:  True\
Feedback: 4.1.1\
Difficulty: Easy\
\
\
\
44.  Linux distinguishes between processes and threads.\
\
Ans:  False\
Feedback: 4.7.2\
Difficulty: Easy\
\
\
\
45.  In Java, data shared between threads is simply declared globally.\
\
Ans:  False\
Feedback: 4.4.3\
Difficulty: Medium\
\
\
\
46. Each thread has its own register set and stack.\
\
Ans: True\
Feedback: 4.1\
Difficulty: Easy\
\
\
\
47. Deferred cancellation is preferred over asynchronous cancellation.\
\
Ans: True\
Feedback: 4.6.3\
Difficulty: Easy\
\
\
\
48. The single benefit of a thread pool is to control the number of threads.\
\
Ans: False\
Feedback: 4.5.1\
Difficulty: Easy\
\
\
\
49. It is possible to create a thread library without any kernel-level support.\
\
Ans: True\
Feedback: 4.4\
Difficulty: Medium
\f2\fs22 \
\
\
\
50. It is possible to have concurrency without parallelism.\
\
And: True\
Feedback: 4.2\
Difficulty: Medium\
\
\
\
51. Amdahl's Law describes performance gains for applications with both a serial and parallel component.\
\
Ans: True\
Feedback: 4.2\
Difficulty: Medium\
\
\
\
52. OpenMP only works for C, C++, and Fortran programs.\
\
Ans: True\
Feedback 4.5.2:\
Difficulty: Medium\
\
\
\
53. Grand Central Dispatch requires multiple threads.\
\
Ans: False\
Feedback: 4.5.3\
Difficulty: Medium\
\
\
\
54. The trend in developing parallel applications is to use implicit threading.\
\
Ans: True\
Feedback: 4.5\
Difficulty: Medium\
\
\
\
55. Task parallelism distributes threads and data across multiple computing cores.\
\
Ans: False\
Feedback: 4.2.2\
Difficulty: Difficult\
\
\
\
6.
\f3 \uc0\u20026 \'a4\'b0\'a4\'5c
\f2 Web
\f3 \'aa\'41\uc0\u21153 \'be\'b9\'a4\'a3\'af\'e0\'a7\'40\u20026 \u21333 \u32447 \'b5\'7b\u36827 \'b5\'7b\u36816 \'a6\'e6\'a1\'48
\f2 \
\
Ans
\f3 \'a1\'47\uc0\u23545 \'a4\'5f\'a7\'40\u20026 \u21333 \u32447 \'b5\'7b\u36827 \'b5\'7b\u36816 \'a6\'e6\'aa\'ba
\f2 Web
\f3 \'aa\'41\uc0\u21153 \'be\'b9\'a1\'41\'a4\'40\'a6\'b8\'a5\'75\'af\'e0\u20026 \'a4\'40\u20010 \'ab\'c8\u25143 \'ba\'dd\'b4\'a3\'a8\'d1\'aa\'41\u21153 \'a1\'43\u36825 \'a5\'69\'af\'e0\u23548 \'ad\'50\'c1\'63\'a6\'a3\'aa\'41\u21153 \'be\'b9\'aa\'ba\u28508 \'a6\'62\'a5\'a8\'a4\'6a\'b5\'a5\'ab\'dd\u26102 \u38388 \'a1\'43
\f2 \
\pard\pardeftab720\ri0\partightenfactor0

\f3 \cf0 \'a4\'cf\uc0\u39304 \'a1\'47
\f2 4.1.1\

\f3 \uc0\u38590 \'ab\'d7\'a1\'47\'a4\'a4\'b5\'a5
\f2 \
\
\
\
27.
\f3 \'a6\'43\'a5\'58\'a6\'68\uc0\u32447 \'b5\'7b\u32534 \'b5\'7b\'aa\'ba\'a5\'7c\'a4\'6a\'a5\'44\'ad\'6e\'c9\'ac\u28857 \'a1\'43\u31616 \'ad\'6e\'b8\'d1\u37322 \'a4\'40\'a4\'55\'a1\'43
\f2 \
\
Ans
\f3 \'a1\'47\'a6\'68\uc0\u32447 \'b5\'7b\u32534 \'b5\'7b\'aa\'ba\'a6\'6e\u22788 \'a4\'c0\u20026 \'a4\'4c\u31867 \'a1\'47\u21709 \u24212 \'a9\'ca\'a1\'41\u36164 \'b7\'bd\'a6\'40\'a8\'c9\'a1\'41\u32463 \u27982 \'a9\'ca\'a9\'4d\'a6\'68\u22788 \'b2\'7a\'be\'b9\'ca\'5e\'a8\'74\u32467 \'cc\'db\'aa\'ba\'a7\'51\'a5\'ce\'a1\'43\u21709 \u24212 \'a9\'ca\'b7\'4e\'a8\'fd\u30528 \'a6\'68\u32447 \'b5\'7b\'b5\'7b\'a7\'c7\'a5\'69\'a5\'48\'a4\'b9\u35768 \'b5\'7b\'a7\'c7\u36816 \'a6\'e6\'a1\'41\'a7\'59\'a8\'cf\'b5\'7b\'a7\'c7\'aa\'ba\'a4\'40\'b3\'a1\'a4\'c0\'b3\'51\'aa\'fd\'a4\'ee\'a1\'43\u24403 \u24212 \'a5\'ce\'b5\'7b\'a7\'c7\'a6\'62\'a6\'50\'a4\'40\'a6\'61\'a7\'7d\'aa\'c5\u38388 \u20869 \'a8\'e3\'a6\'b3\'a6\'68\u20010 \'a4\'a3\'a6\'50\'aa\'ba\'ac\'a1\u21160 \u32447 \'b5\'7b\u26102 \'a1\'41\'b4\'4e\u20250 \u21457 \'a5\'cd\u36164 \'b7\'bd\'a6\'40\'a8\'c9\'a1\'43\u32447 \'b5\'7b\'a6\'40\'a8\'c9\'a5\'a6\u20204 \'a9\'d2\u23646 \'aa\'ba\u36827 \'b5\'7b\'aa\'ba\u36164 \'b7\'bd\'a1\'43\'a6\'5d\'a6\'b9\'a1\'41\u21019 \'ab\'d8\'b7\'73\u32447 \'b5\'7b\'a4\'f1\'b7\'73\u36827 \'b5\'7b\'a7\'f3\u32463 \u27982 \'a1\'43\'b3\'cc\'a6\'5a\'a1\'41\u21333 \u32447 \'b5\'7b\u36827 \'b5\'7b\'a5\'75\'af\'e0\'a6\'62\'a4\'40\u20010 \u22788 \'b2\'7a\'be\'b9\'a4\'57\u25191 \'a6\'e6\'a1\'41\'a6\'d3\'a4\'a3\'ba\'de\u23454 \u38469 \'a6\'73\'a6\'62\'aa\'ba\u22788 \'b2\'7a\'be\'b9\u25968 \'b6\'71\'a1\'43\'a6\'68\u20010 \u32447 \'b5\'7b\'a5\'69\'a5\'48\'a6\'62\'a6\'68\u20010 \u22788 \'b2\'7a\'be\'b9\'a4\'57\u36816 \'a6\'e6\'a1\'41\u20174 \'a6\'d3\'b4\'a3\'b0\'aa\'ae\'c4\'b2\'76\'a1\'43
\f2 \

\f3 \'a4\'cf\uc0\u39304 \'a1\'47
\f2 4.1.2\

\f3 \uc0\u38590 \'ab\'d7\'a1\'47\'a7\'78\u38590 
\f2 \
\
\
\
28.
\f3 \'a5\'69\'a5\'48\'b3\'71\uc0\u36807 \'ad\'fe\u20004 \'cf\'fa\'a4\'a3\'a6\'50\'aa\'ba\'a4\'e8\'a6\'a1\u23454 \u29616 \u32447 \'b5\'7b\u24211 \'a1\'48
\f2 \
\
Ans
\f3 \'a1\'47\uc0\u23454 \u29616 \u24211 \'aa\'ba\'b2\'c4\'a4\'40\'cf\'fa\'a7\'de\u26415 \'af\'41\'a4\'ce\'da\'cc\'ab\'4f\u24211 \'aa\'ba\'a9\'d2\'a6\'b3\'a5\'4e\u30721 \'a9\'4d\u25968 \'d5\'75\u32467 \'cc\'db\'b3\'a3\u39547 \'af\'64\'a6\'62\u27809 \'a6\'b3\u20869 \'ae\'d6\'a4\'e4\'ab\'f9\'aa\'ba\'a5\'ce\u25143 \'aa\'c5\u38388 \'a4\'a4\'a1\'43\'a5\'74\'a4\'40\'cf\'fa\'a4\'e8\'aa\'6b\'ac\'4f\u23454 \u29616 \'be\'de\'a7\'40\'a8\'74\u32479 \'aa\'bd\'b1\'b5\'a4\'e4\'ab\'f9\'aa\'ba\u20869 \'ae\'d6\u32423 \u24211 \'a1\'41\'a5\'48\'ab\'4b\'a5\'4e\u30721 \'a9\'4d\u25968 \'d5\'75\u32467 \'cc\'db\'a6\'73\'a6\'62\'a4\'5f\u20869 \'ae\'d6\'aa\'c5\u38388 \'a4\'a4\'a1\'43
\f2 \

\f3 \'a4\'cf\uc0\u39304 \'a1\'47
\f2 4.4\

\f3 \uc0\u38590 \'ab\'d7\'a1\'47\'a4\'a4\'b5\'a5
\f2 \
\
\
\
29.
\f3 \'b4\'79\'ad\'7a\'a6\'62
\f2 Java
\f3 \'a4\'a4\uc0\u21019 \'ab\'d8
\f2 Thread
\f3 \uc0\u23545 \'b6\'48\'aa\'ba\u20004 \'cf\'fa\'a7\'de\u26415 \'a1\'43
\f2 \
\
Ans
\f3 \'a1\'47\'a4\'40\'cf\'fa\'a4\'e8\'aa\'6b\'ac\'4f\uc0\u21019 \'ab\'d8\'a4\'40\u20010 \'ac\'a3\'a5\'cd\'a6\'db
\f2 Thread
\f3 \uc0\u31867 \'aa\'ba\'b7\'73\u31867 \'a1\'41\'a6\'7d\'c2\'d0\u30422 \'a8\'e4
\f2 run
\f3 \'a1\'5d\'a1\'5e\'a4\'e8\'aa\'6b\'a1\'43\'a5\'74\'a4\'40\'cf\'fa
\f2  - 
\f3 \'a4\'5d\'ac\'4f\'a7\'f3\'b1\'60\'a5\'ce\'aa\'ba
\f2  - 
\f3 \'a7\'de\uc0\u26415 \'ac\'4f\'a9\'77\u20041 \'a4\'40\u20010 \u23454 \u29616 
\f2 Runnable
\f3 \'b1\'b5\'a4\'66\'aa\'ba\uc0\u31867 \'a1\'43\u24403 \u31867 \u23454 \u29616 
\f2 Runnable
\f3 \uc0\u26102 \'a1\'41\'a5\'a6\'a5\'b2\u39035 \'a9\'77\u20041 
\f2 run
\f3 \'a1\'5d\'a1\'5e\'a4\'e8\'aa\'6b\'a1\'43\uc0\u23454 \u29616 
\f2 run
\f3 \'a1\'5d\'a1\'5e\'a4\'e8\'aa\'6b\'aa\'ba\'a5\'4e\uc0\u30721 \'ac\'4f\'a7\'40\u20026 \u21333 \u29420 \'aa\'ba\u32447 \'b5\'7b\u36816 \'a6\'e6\'aa\'ba\'a5\'4e\u30721 \'a1\'43
\f2 \

\f3 \'a4\'cf\uc0\u39304 \'a1\'47
\f2 4.4.3\

\f3 \uc0\u38590 \'ab\'d7\'a1\'47\'a4\'a4\'b5\'a5
\f2 \
\
\
\
30.
\f3 \'a6\'62
\f2 Java
\f3 \'a4\'a4\'a1\'41\uc0\u20026 \'b7\'73\'aa\'ba
\f2 Thread
\f3 \uc0\u23545 \'b6\'48\u35843 \'a5\'ce
\f2 start
\f3 \'a1\'5d\'a1\'5e\'a4\'e8\'aa\'6b\uc0\u20250 \'b0\'b5\'a4\'b0\'a4\'5c\'a1\'48
\f2 \
\
Ans
\f3 \'a1\'47\uc0\u20026 \'b7\'73\'aa\'ba
\f2 Thread
\f3 \uc0\u23545 \'b6\'48\u35843 \'a5\'ce
\f2 start
\f3 \'a1\'5d\'a1\'5e\'a4\'e8\'aa\'6b\'ad\'ba\'a5\'fd\'a4\'c0\'b0\'74\uc0\u20869 \'a6\'73\'a6\'7d\'a6\'62
\f2 JVM
\f3 \'a4\'a4\'aa\'ec\'a9\'6c\'a4\'c6\'a4\'40\uc0\u20010 \'b7\'73\u32447 \'b5\'7b\'a1\'43\'b1\'b5\'a4\'55\u26469 \'a1\'41\'a5\'a6\u35843 \'a5\'ce
\f2 run
\f3 \'a1\'5d\'a1\'5e\'a4\'e8\'aa\'6b\'a1\'41\'a8\'cf\uc0\u32447 \'b5\'7b\'a6\'b3\u36164 \'ae\'e6\'a5\'d1
\f2 JVM
\f3 \uc0\u36816 \'a6\'e6\'a1\'43\u35831 \'aa\'60\'b7\'4e\'a1\'41\'a5\'c3
\f4 \'d4\'b6\'b2\'bb\'bb\'e1\'d6\'b1\'bd\'d3\'b5\'f7\'d3\'c3
\f2 run
\f3 \'a1\'5d\'a1\'5e\'a4\'e8\'aa\'6b\'a1\'43\'a6\'d3\'ac\'4f\uc0\u35843 \'a5\'ce
\f2 start
\f3 \'a1\'5d\'a1\'5e\'a4\'e8\'aa\'6b\'a1\'41\'b5\'4d\'a6\'5a\uc0\u35843 \'a5\'ce
\f2 run
\f3 \'a1\'5d\'a1\'5e\'a4\'e8\'aa\'6b\'a1\'43
\f2 \

\f3 \'a4\'cf\uc0\u39304 \'a1\'47
\f2 4.4.3\

\f3 \uc0\u38590 \'ab\'d7\'a1\'47\'a4\'a4\'b5\'a5
\f2 \
\
\
\
31.
\f3 \'ac\'59\'a8\'c7
\f2 UNIX
\f3 \'a8\'74\uc0\u32479 \'a6\'b3\u20004 \u20010 \'aa\'a9\'a5\'bb\'aa\'ba
\f2 fork
\f3 \'a1\'5d\'a1\'5e\'a1\'43\'b4\'79\'ad\'7a\'a8\'43\uc0\u20010 \'aa\'a9\'a5\'bb\'aa\'ba\'a5\'5c\'af\'e0\'a1\'41\'a5\'48\'a4\'ce\'a6\'70\'a6\'f3\u20915 \'a9\'77\'a8\'cf\'a5\'ce\'ad\'fe\u20010 \'aa\'a9\'a5\'bb\'a1\'43
\f2 \
\
Ans
\f3 \'a1\'47
\f2 fork
\f3 \'a1\'5d\'a1\'5e\'aa\'ba\'a4\'40\uc0\u20010 \'aa\'a9\'a5\'bb\'ce\'60\'a8\'ee\'a9\'d2\'a6\'b3\u32447 \'b5\'7b\'a1\'41\'a5\'74\'a4\'40\u20010 \'aa\'a9\'a5\'bb\'a5\'75\'ce\'60\'a8\'ee\u35843 \'a5\'ce
\f2 fork
\f3 \'a1\'5d\'a1\'5e\'a8\'74\uc0\u32479 \u35843 \'a5\'ce\'aa\'ba\u32447 \'b5\'7b\'a1\'43
\f2  fork
\f3 \'a1\'5d\'a1\'5e\'aa\'ba\uc0\u20004 \u20010 \'aa\'a9\'a5\'bb\'a4\'a4\'aa\'ba\'ad\'fe\'a4\'40\u20010 \'a8\'fa\u20915 \'a4\'5f\u24212 \'a5\'ce\'b5\'7b\'a7\'c7\'a1\'43\'a6\'70\'aa\'47\'a6\'62\'a4\'c0\'a4\'65\'a6\'5a\'a5\'df\'a7\'59\u35843 \'a5\'ce
\f2 exec
\f3 \'a1\'5d\'a1\'5e\'a1\'41\uc0\u21017 \'a4\'a3\'bb\'dd\'ad\'6e\'ce\'60\'a8\'ee\'a9\'d2\'a6\'b3\u32447 \'b5\'7b\'a1\'41\'a6\'5d\u20026 
\f2 exec
\f3 \'a1\'5d\'a1\'5e\uc0\u21442 \u25968 \'a4\'a4\'ab\'fc\'a9\'77\'aa\'ba\'b5\'7b\'a7\'c7\u23558 \'b4\'c0\u25442 \u36827 \'b5\'7b\'a1\'43\'a6\'fd\'ac\'4f\'a1\'41\'a6\'70\'aa\'47\'a4\'c0\'d6\'c3\u36827 \'b5\'7b\'a6\'62\'a4\'c0\'a4\'65\'a6\'5a\u27809 \'a6\'b3\u35843 \'a5\'ce
\f2 exec
\f3 \'a1\'5d\'a1\'5e\'a1\'41\uc0\u21017 \u21333 \u29420 \'aa\'ba\u36827 \'b5\'7b\u24212 \u35813 \'ce\'60\'a8\'ee\'a9\'d2\'a6\'b3\u32447 \'b5\'7b\'a1\'43
\f2 \

\f3 \'a4\'cf\uc0\u39304 \'a1\'47
\f2 4.6.1\

\f3 \uc0\u38590 \'ab\'d7\'a1\'47\'a7\'78\u38590 
\f2 \
\
\
\
32.
\f3 \'c9\'4f\'c9\'dd\'a8\'42\'a8\'fa\'ae\'f8\'ac\'db\'a4\'f1\'a1\'41\'a9\'b5
\f4 \'b3\'d9\'c8\'a1\'cf\'fb\'c8\'e7\'ba\'ce\'c8\'b7\'b1\'a3\'cf\'df\'b3\'cc\'d6\'d5\'d6\'b9\'d2\'d4\'d3\'d0\'d0\'f2\'b5\'c4\'b7\'bd\'ca\'bd\'b7\'a2\'c9\'fa\'a3\'bf
\f2 \
\
Ans
\f3 \'a1\'47\'a6\'62\'c9\'dd\'a8\'42\'a8\'fa\'ae\'f8\'a4\'a4\'a1\'41\uc0\u32447 \'b5\'7b\'a5\'df\'a7\'59\'b3\'51\'a8\'fa\'ae\'f8\'a5\'48\u21709 \u24212 \'a8\'fa\'ae\'f8\u35831 \'a8\'44\'a1\'43\u27809 \'a6\'b3\'ab\'4f\u38505 \'a6\'62\u25968 \'d5\'75\'a7\'f3\'b7\'73\'a9\'ce\'a8\'e4\'a5\'4c\u28508 \'a6\'62\'a6\'4d\u38505 \'b1\'a1\u20917 \'a4\'55\'a5\'a6\u27809 \'a6\'b3\'b0\'68\'a5\'58\'a1\'43\'a6\'62\'a9\'b5
\f4 \'b3\'d9\'c8\'a1\'cf\'fb\'d6\'d0\'a3\'ac\'cf\'df\'b3\'cc\'c2\'d6\'d1\'af\'cb\'fc\'ca\'c7\'b7\'f1\'d3\'a6\'b8\'c3\'d6\'d5\'d6\'b9\'a1\'a3\'d5\'e2\'d1\'f9\'a3\'ac\'bf\'c9\'d2\'d4\'d4\'da\'b7\'bd\'b1\'e3\'b5\'c4\'ca\'b1\'ba\'f2\'c8\'a1\'cf\'fb\'cf\'df\'b3\'cc\'a1\'a3
\f2 \

\f3 \'a4\'cf\uc0\u39304 \'a1\'47
\f2 4.6.3\

\f3 \uc0\u38590 \'ab\'d7\'a1\'47\'a4\'a4\'b5\'a5
\f2 \
\
\
\
33.
\f3 \'a4\'b0\'a4\'5c\'ac\'4f\uc0\u32447 \'b5\'7b\'a6\'c0\'a1\'41\u20026 \'a4\'b0\'a4\'5c\'a8\'cf\'a5\'ce\'a5\'a6\'a1\'48
\f2 \
\
Ans
\f3 \'a1\'47\uc0\u32447 \'b5\'7b\'a6\'c0\'ac\'4f\'a6\'62\u36827 \'b5\'7b\u21551 \u21160 \u26102 \u21019 \'ab\'d8\'aa\'ba\u32447 \'b5\'7b\'b6\'b0\'a6\'58\'a1\'41\'a5\'a6\u20204 \'b5\'a5\'ab\'dd\'a4\'75\'a7\'40\'a4\'c0\'b0\'74\u32473 \'a5\'a6\u20204 \'a1\'43\u36825 \'a4\'b9\u35768 \'a4\'48\u20204 \u23545 \'c9\'4f\u36827 \'b5\'7b\u20851 \u32852 \'aa\'ba\'a6\'7d\u21457 \u32447 \'b5\'7b\u25968 \'b6\'71\u36827 \'a6\'e6\'ad\'ad\'a8\'ee\'a1\'41\'a6\'7d\u20943 \'a4\'d6\u21019 \'ab\'d8\'b7\'73\u32447 \'b5\'7b\'a6\'7d\'a6\'62\u32456 \'a4\'ee\u26102 \u38144 \u27585 \'a5\'a6\u20204 \'aa\'ba\u24320 \u38144 \'a1\'43
\f2 \

\f3 \'a4\'cf\uc0\u39304 \'a1\'47
\f2 4.5.1\

\f3 \uc0\u38590 \'ab\'d7\'a1\'47\'a4\'a4\'b5\'a5
\f2 \
\
\
\
34. Windows
\f3 \'a4\'a4\uc0\u32447 \'b5\'7b\'aa\'ba\'a4\'40\'af\'eb\u32452 \'a5\'f3\'ac\'4f\'a4\'b0\'a4\'5c\'a1\'48
\f2 \
\
Ans
\f3 \'a1\'47\uc0\u35813 \u32447 \'b5\'7b\'a5\'d1\'a4\'40\u20010 \'b0\'df\'a4\'40\'aa\'ba
\f2 ID
\f3 \'a1\'41\'a4\'40\uc0\u20010 \'a5\'4e\'aa\'ed\u22788 \'b2\'7a\'be\'b9\u29366 \u24577 \'aa\'ba\'b1\'48\'a6\'73\'be\'b9\'b6\'b0\'a1\'41\'a4\'40\u20010 \'a5\'ce\u25143 \'bc\'d2\'a6\'a1\'aa\'ba\'a5\'ce\u25143 \'b0\'ef\u26632 \'a1\'41\'a4\'40\u20010 \'a5\'ce\'a4\'5f\u20869 \'ae\'d6\'bc\'d2\'a6\'a1\'aa\'ba\u20869 \'ae\'d6\'b0\'ef\u26632 \'a1\'41\'a5\'48\'a4\'ce\'a4\'40\u20010 \'a5\'d1\u36816 \'a6\'e6\u26102 \u24211 \'a9\'4d\u21160 \u24577 \u38142 \'b1\'b5\u24211 \'a8\'cf\'a5\'ce\'aa\'ba\'a8\'70\'a6\'b3\'a6\'73\u20648 \u21306 \u32452 \'a6\'a8\'a1\'43
\f2  
\f3 \'a1\'43
\f2 \

\f3 \'a4\'cf\uc0\u39304 \'a1\'47
\f2 4.4.2\

\f3 \uc0\u38590 \'ab\'d7\'a1\'47\'a4\'a4\'b5\'a5
\f2 \
\
\
\
35.
\f3 \'b4\'79\'ad\'7a
\f2 fork
\f3 \'a1\'5d\'a1\'5e\'a9\'4d
\f2 clone
\f3 \'a1\'5d\'a1\'5e
\f2 Linux
\f3 \'a8\'74\uc0\u32479 \u35843 \'a5\'ce\'a4\'a7\u38388 \'aa\'ba\u21306 \u21035 \'a1\'43
\f2 \
\
Ans
\f3 \'a1\'47
\f2 fork
\f3 \'a1\'5d\'a1\'5e\'a8\'74\uc0\u32479 \u35843 \'a5\'ce\'a5\'ce\'a4\'5f\'ce\'60\'a8\'ee\u36827 \'b5\'7b\'a1\'43
\f2  clone
\f3 \'a1\'5d\'a1\'5e\'a8\'74\uc0\u32479 \u35843 \'a5\'ce\'aa\'ba\'a6\'e6\u20026 \u31867 \'a6\'fc\'a1\'41\'b0\'a3\'a4\'46\u21019 \'ab\'d8\'a4\'40\u20010 \u21333 \u29420 \'aa\'ba\u36827 \'b5\'7b\u26469 \'a6\'40\'a8\'c9\u35843 \'a5\'ce\u36827 \'b5\'7b\'aa\'ba\'a6\'61\'a7\'7d\'aa\'c5\u38388 \'a1\'41\'a6\'d3\'a4\'a3\'ac\'4f\u21019 \'ab\'d8\u36827 \'b5\'7b\'aa\'ba\'b0\'c6\'a5\'bb\'a1\'43
\f2 \

\f3 \'a4\'cf\uc0\u39304 \'a1\'47
\f2 4.7.2\

\f3 \uc0\u38590 \'ab\'d7\'a1\'47\'a4\'a4\'b5\'a5
\f2 \
\
\
\
\pard\pardeftab720\ri0\partightenfactor0

\f0\fs24 \cf0 36. Multicore systems present certain challenges for multithreaded programming. Briefly describe these challenges.\
\
Ans: Multicore systems have placed more pressure on system programmers as well as application developers to make efficient use of the multiple computing cores. These challenges include determining how to divide applications into separate tasks that can run in parallel on the different cores. These tasks must be balanced such that each task is doing an equal amount of work. Just as tasks must be separated, data must also be divided so that it can be accessed by the tasks running on separate cores. So that data can safely be accessed, data dependencies must be identified and where such dependencies exist, data accesses must be synchronized to ensure the safety of the data. Once all such challenges have been met, there remains considerable challenges testing and debugging such applications.\
Feedback: 4.2.1\
Difficulty: Difficult\
\
\
\
37. Distinguish between parallelism and concurrency.\
\
Ans: A parallel system can perform more than one task simultaneously. A concurrent system supports more than one task by allowing multiple tasks to make progress. \
Feedback: 4.2\
Difficulty: Medium\
\
\
\
38. Distinguish between data and task parallelism.\
\
And: Data parallelism involves distributing subsets of the same data across multiple computing cores and performing the same operation on each core. Task parallelism involves distributing tasks across the different computing cores where each task is performing a unique operation.\
Feedback: 4.2.2\
Difficulty: Difficult\
\
\
\
39. Describe how OpenMP is a form of implicit threading.\
\
Ans: OpenMP provides a set of compiler directives that allows parallel programming on systems that support shared memory. Programmers identify regions of code that can run in parallel by placing them in a block of code that begins with the directive 
\f1 #pragma omp parallel
\f0 . When the compiler encounters this parallel directive, it creates as many threads as there are processing cores in the system.\
Feedback: 4.5.2\
Difficulty: Difficult\
\
\
\
40. Describe how Grand Central Dispatch is a form of implicit threading.\
\
Ans: Grand Central Dispatch (GCD) is a technology for Mac OS X and iOS systems that is a combination of extensions to the C language, an API, and a runtime library that allows developers to construct "blocks" -  regions of code that can run in parallel. GCD then manages the parallel execution of blocks in several dispatch queues.\
Feedback: 4.5.3\
Difficulty: Difficult\
}